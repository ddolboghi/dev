- 쿠버네티스는 개념 이해 필요
- 설정 화면 캡처해놓기
- ec2 docker로 실행하기
- kafka
- 컨테이너 많음
- ec2 설정
	- t3 large
	- 우분투
	- 메모리: 32gb (스토리지 구성에서 설정), swap 메모리 설정하기
	- cpu: gp2
- 요금 청구: aws 청구서, 주민등록등본(뒷자리 가리기), 통장사본, 상한선 30
- 인수인계서 만들어 놓기
---
#  MSA 사용하는 이유
> [!tip] MSA로 해결하려는 목표는 기술적인 것이 아니다.
- 거대한 조직의 개발 생산성을 유지하거나 작은 조직들이 독립적이고 빠르게 나아가 하기 위해
# MSA 조건
> [!tip] 아키텍처 스타일은 시스템의 상황과 목표에 맞게 최적화되어야 하는 것이지 아키텍처 스타일을 그대로 반영하는 것이 아니다. 결국 중요한 것은 시스템의 목표를 어떻게 달성하는가이다.
- 각 서비스는 비즈니스 기능단위로 나누어야함
- 각 서비스 간에 임의적인 접근이 불가능하도록 격리해야함
- 데이터베이스를 분리하여 서로 조인하지 못하게 차단해야함
- 외부에 영향을 주는 서비스에서 변경이 있을때, 기존 API가 하위 호환성을 가질 수 있도록 해야하며 더 신중하고 점진적인 배포 방식 고려
- CD(continuous delivery) 같은 최신 소프트웨어 배포 방식을 이해해야함
# MSA와 직접적인 관련이 없는 것들
- REST API  -> API는 MSA를 차별화하는 특징이 아님
- 재사용 관점에서 MSA를 바라보는 것 -> 재사용만을 위해서 시스템을 서비스로 분리할 필요 없음
- 클라우드 네이티브 애플리케이션 -> 작은 모놀리식 시스템도 클라우드 인프라를 사용한다면 이를 잘 활용할 수 있는 구조를 갖춰야 함
# MSA에 대한 사실과 오해
## 서비스 간 통신이 많으면 속도가 느리다.
- 클라이언트에서 여러 서비스의 데이터가 필요할때 병렬로 REST API를 호출하면 느리지 않음
- 서비스간 통신에서 N+1 문제를 방지하려면 일괄 API 요청
```java
//[GET] /api/v1/users/101,102,103,...,120

@GetMapping("/{usersIds}")
public ResponseEntity<?> getUsers(@Param("usersIds") List<Ling> ids) {
	....
}
```
- 스프링 controller에서 URI에 콤마로 구분하여 값을 전달하면 이 값들을 리스트나 배열에 담을 수 있음
- 잘 변하지 않는 공통 데이터는 로컬 캐시를 활용해 조회 속도 개선하기
- 로컬 캐시는 요청이 급격히 몰리는 경우에 서비스 부하를 낮추기 위함임
## 자동으로 롤백되지 않는다.
> [!TIP] ACID 트랜잭션이란?
> - Atomicity(원자성): 트랜잭션을 실행했을때 성공적으로 완료하거나 시작 전과 동일한 상태 보장
> - Consistancy(일관성): 트랜잭션이 성공적으로 완료되면 데이터가 일관적인 상태 유지
> - Isolation(독립성): 여러 트랜잭션이 서로 간섭하지 않도록 보장
> - Durability(지속성): 트랜잭션이 완료된 데이터를 영구 보존

- 여러 서비스에 걸친 트랜잭션이 중간에 실패하면 다른 서비스에서 발생한 트랜잭션을 취소하는 보상 트랜잭션을 실행해야함
- 사실 모놀리식 시스템이 네트워크로 통신할 때도 항상 해오던 일임
- 서비스 간의 트랜잭션에서는 원자성과 독립성을 유의해야함
- 실제로 보상 트랜잭션이 필요한 경우는 생각보다 적음
	- 각 서비스는 응집도를 높게 구성하기 때문에 서비스 간 참조가 많지 않음
	- 트랜잭션의 중요도가 높은 경우 해당 트랜잭션이 발생하는 업무를 하나의 서비스에 배치기
## 동시성 이슈
- 트랜잭션을 진행하는 동안 다른 트랜잭션으로 인해 데이터가 변경되지 않도록 막아야함
- 트랜잭션이 진행되거나 롤백되는 동안 데이터가 조회되지 않도록 막아야함
- `SELECT FOR UPDATE`로 락을 걸 수 있지만, 전체 시스템 속도를 저하시킴
- 애플리케이션 단에서 데이터를 변경하지 못하게 하는 API를 만들어야함
- 트랜잭션 중인 값이 조회되지 않도록 데이터의 상태 값 추가
# 데이터베이스 락, 커넥션 풀 관리
## 비관적 잠금 시 DB 커넥션과 Row Lock 생성 주기
```java
@Transactional // DB 커넥션 점유
void createSource(Course course) {
	...
	couseMapper.create(...); // 락 생성
	...
	memberGateway.addManager(...);
	boardGateway.addBoard(...);
} // DB 커넥션 해제, 락 해제
```
1. `@Transactional`로 스프링 프레임워크가 서버의 데이터베이스 커넥션 풀에서 커넥션 하나 점유
2. Mapper로 테이블에 데이터를 INSERT하면 해당 레코드에 락 생성
3. 메서드가 종료되면서 스프링 프레임워크가 데이터베이스에 커밋하면 레코드 락 해제되고 커넥션 반환됨

- 다른 서비스에서 문제가 발생하면 호출한 REST API가 대기 큐에 계속 대기 상태로 있고 DB 커넥션과 Row Lock도 계속 잡혀있어 서비스의 다른 기능이 데이터베이스 커넥션을 얻지 못하거나, 락이 풀리지 않아 서비스가 느려지거나 장애 발생 가능
## 낙관적 잠금 시 DB 커넥션과 Row Lock 생성 주기
```java
void createSource(Course course) {
	...
	transactionManager.getTransaction(...); // 1. DB 커넥션 점유
	...
	courseRepository.save(...);// 2
	...
	memberGatesay.addManager(...);
	boardGateway.addBoard(...);
	transactionManager.commit(...); // 3. DB 커넥션 해제, 락 생성/해제
}
```
1. `getTransaction`메서드가 실행되면 DB 커넥션 풀에서 하나의 커넥션 점유
2. 나중에 INSERT할때 비교할 수 있도록 데이터를 SELECT하여 버전 확인하기 때문에 Row Lock 생성되지 않음
3. 커밋 실행 시 실제 INSERT문 작동, Row Lock 순간적으로 생성 및 해제되었다가 커밋이 실행되면서 DB 커넥션 반환됨

- REST API 호출이 길어져도 Row Lock은 짧게 점유하지만 DB 커넥션 점유 시간은 길어짐
## 커밋 순서 바꾸기
### 문제점
- 트랜잭션 중간에 호출하는 REST API를 Time Out으로 처리해도 반드시 일정 시간이 걸리기 때문에 호출하는 REST API가 많을수록 DB 커넥션과 로우락 점유 시간이 늘어남
### 해결 방법
- **로컬 데이터베이스의 커밋을 먼저 실행**해서 DB 커넥션을 일찍 반환하고 로우락 최소화
```java
public void createCourse(Course curse) {
	Set<String> txLog = new HashSet<>(); // 트랜잭션 구별 용도

	String courseId = null;
	courseId = course.getId();

	courseRepository.save(course); // DB 커넥션 점유, 락 생성
	try {
		transactionmanger.commit(...); // DB 커넥션 반환, 락 해제
	} catch (Exception exception) {
		transactionManger.rollback(...);
		throw new RuntimeException("Falied to create a course", exception);
	}

	try {
		memberGateway.addManager(courseId, loginUser);
		txLog.add("managerAdded");

		boardGateway.addBoard(courseId, loginUser);
		txLog.add("boardAdded");
	} catch (Exception originalException) {
		// 보상 트랜잭션
		if(txLog.contains("managerAdded")) {
			compensateAddManager(courseId, loginUser);
		}
		
		compensateSaveCourse(courseId, loginUser); // REST API 실패 시 저장된 정보 삭제
		throw new RuntimeException("Failed to create a course", originalException);
	}
}
```

```java
private void compensateSaveCourse(String courseId, UserDetails loginUser) {
	try {
		courseRepository.deleteById(courseId);
	} catch (RuntimeException compensationException) {
		log.error("COMPENSATION TRANSACTION ERROR {}", compensationException);
	}
}
```
- 외부 서비스의 REST API를 많이 호출하거나 API 실행 시간이 길고 균일하지 않다면 안정적인 애플리케이션을 위해 직접 커밋하고 삭제하는 방법을 선택할 수도 있음
- 일반적으로 데이터베이스의 롤백 기능 사용(e.g. `@Transactional`)
- Saga 패턴
	- 보상 트랜잭션 자동화
	  e.g.데이터를 변경하는 코드와 보상 트랜잭션을 짝으로 묶어놓고, 데이터를 변경하다 에러가 발생하면 자동으로 실행했던 순서의 역순으로 보상 트랜잭션 실행
	- 보상 트랜잭션을 자동으로 실행해주는 것만으로 보상 트랜잭션이 실패하지 않도록 보장해주지 못하고, 여러 트랜잭션이 동시에 발생했을때 서로 섞이지 않도록 보호해줄 수 없음
# 보상 트랜잭션 최적화하기
![[보상트랜잭션.png]]
보상 트랜잭션은 일시적인 네트워크나 서버 오류로 실패할 수 있음([참고](https://tech.kakaopay.com/post/msa-transaction/))
![[보상트랜잭션_실패.png]]
더 이상 시도할 방법이 없으면 다음에 데이터를 정리할 수 있도록 기록해두고 필요시 사용자에게 안내 메시지 표시하거나, 일정 시간 후에 재시도할 수 있도록 구현해야함
## 보상 트랜잭션이 불필요한 경우
- 서비스A에서 WRITE 후 서비스B에서 WRITE할때
	- A에서 실패하면 B가 실행되지 않음
	- B에서 실패하면 B내에서 자동 롤백되고 A는 REST API 응답 결과를 받아 롤백하면 됨
	![보상트랜잭션_불필요1](보상트랜잭션_불필요1)
- 다른 서비스를 조회만 할때
## 보상 트랜잭션이 필요한 경우
- 서비스에서 WRITE 중간에 다른 서비스에서 WRITE할때![보상트랜잭션_필요1](보상트랜잭션_필요1)
- 서비스에서 WRITE 후 여러 서비스에서 순서대로 WRITE할때![보상트랜잭션_필요2](보상트랜잭션_필요2)
## 보상 트랜잭션 줄이기
### 코드 배치 바꾸기
> [!TIP] 보상 트랜잭션은 WRITE 작업 순서의 영향을 받는다.
> - WRITE 작업을 자동으로 롤백해주는 로컬 데이터베이스의 작업을 먼저 처리하고 다른 서비스의 WRITE 작업을 호출하는게 좋다. 
> - SMS 발송이나 이메일 발송처럼 복구 불가능한 트랜잭션은 가능한 마지막으로 처리하는게 좋다.

- WRITE 작업 전에 가능한 많은 일을 해두면 불필요한 보상 트랜잭션을 줄일 수 있음
	- 사용자 권한 체크, 입력값 검증, WRITE에 필요한 데이터 조회 등

```java
void transaction() {
	// before WRITE
	// 사용자 권한 체크
	// 입력값 검증
	// 데이터 조회

	// WRITING
	// 자동으로 취소되는 것
	// 취소 가능한 것
	// 취소 불가한 것
}
```
### 이벤트 적용하기
- 반드시 하나의 트랜잭션으로 묶을 필요 없는 것들을 이벤트로 분리?
- 이벤트를 생성하는 트랜잭션은 이벤트 생성과 동시에 트랜잭션 종료되고 이벤트 수신 서비스는 각자 서비스 내에서 롤백 가능
- Transactional Outbox Pattern: 이벤트 발송을 트랜잭션 중에 직접하지 않고, DB에 발송 요청을 저장해놓고 백그라운드로 이벤트 전송 -> 이벤트 생성을 포함하는 트랜잭션에 대한 보상 트랜잭션이 필요없음 ??
![보상트랜잭션_이벤트](보상트랜잭션_이벤트)
# 중단한 WRITE 작업 재시도하기
- 사용자가 동일한 요청을 재시도해서 DB에 같은 데이터가 생성될 수 있음
  e.g. 사용자가 주문을 하다가 시스템의 반응이 없어 재시도한 결과 2개의 주문 생성
- 서버가 이전 요청을 정상적으로 처리해도 사용자는 이를 알지 못함
- 마이크로서비스에서 time out 에러 등으로 인해 API를 종료한 경우, 외부 서비스의 DB에는 데이터가 생성됐을 수 있음

> [!tip] WRITE작업을 하는 API는 멱등성을 갖추게 구현해야함
> - 멱등성: 어떤 작업을 여러 번 실행하더라도 결과가 동일한 것
> - 사용자가 같은 요청을 시도한다는 걸 서버가 알 수 있어야함
> - 요청마다 중복되지 않는 ID를 생성해야함

API가 호출되었을때 로컬 데이터베이스에 동일한 ID를 가진 데이터가 있다면:
- 추가로 생성하지 않고 그대로 201(CREATED) 응답
- 같은 데이터가 있다는 에러를 반환하고 호출한 서비스는 이를 에러로 처리하지 않는 식으로 구현
# 이벤트를 사용한 트랜잭션 실행
- 이벤트 기반 트랜잭션은 재시도가 간단해지고 서비스의 API 응답 지연으로 인한 장애도 발생하지 않음
- 트랜잭션의 상태를 파악하기 위해 지속해서 조회하거나 이벤트를 받아야하고, 문제가 발생하는 경우 다른 서비스의 담당자와 함께 로그를 살펴보고 조치해야함
- 이벤트에 익숙하지 않다면 기본적으로 API로 트랜잭션을 처리하고 필요한 경우에만 이벤트 적용

과정 서비스에서 과정 정보를 생성하면 멤버 서비스에서 과정 정보와 과정 담당자 정보를 함께 저장하고, 게시판 서비스에서 과정 정보와 게시판 정보를 저장하는 예시
![[이벤트기반_트랜잭션_시작.png]]
1. 트랜잭션 시작(a1)
2. WRITE 작업 수행(a2): 로컬 DB에 데이터 저장
3. WRITE 작업 완료 이벤트를 이벤트 큐에 등록(a3)
4. 트랜잭션의 상태를 진행 중으로 설정(a4)
5. 트랜잭션 커밋(a5)
6. 트랜잭션 ID와 함께 결과 반환(a6)
7. 트랜잭션 상태를 주기적으로 확인(a7)

![[이벤트기반_트랜잭션_진행.png]]
8. 대상 서비스들이 WRITE 작업 완료 이벤트 수신(b1, c1)
9. 각 대상 서비스에서 WRITE 작업 수행(b2, c2)
10. 각 대상 서비스에서 WRITE 작업 완료 이벤트 발송(b3, c3)
11. 모 서비스에서 대상 서비스의 완료 이벤트 수신(d1)
12. 트랜잭션 상태를 완료로 변경(d2)

> [!tip] 이벤트 기반 트랜잭션도 멱등성을 지켜야한다.
> - 대상 서비스에서 정상적으로 WRITE 작업을 수행해도 모 서비스에서 결과를 받지 못하면 같은 이벤트를 재시도한다.
> - 대상 서비스가 같은 이벤트를 여러 번 전달받아도 동일한 결과를 반환해야 한다.
## 대상 서비스에서 일시적인 오류가 발생할때
- API로 트랜잭션을 실행할때 재시도할 경우 **API를 호출하는 서비스는 대상 서비스가 어떤 상황에 있는지 판단하기 어려워** 재시도하는데 한계가 있음
  e.g. 대상 서비스가 과부하를 받아서 API 요청이 실패하거나 응답이 지연되었는데 재시도를 목적으로 반복해서 API를 호출한다면 외부 서비스는 더 어려운 상황에 빠질 수 있음
- 이벤트 기반 트랜잭션은 **대상 서비스가 가능한 타이밍에 스스로 이벤트를 가져가**므로 재시도에 대한 부담이 적음
- 이벤트 기반 트랜잭션은 **서비스의 스레드가 불필요한 대기를 하지 않아** 서비스의 안정성 개선

![[이벤트기반_트랜잭션_오류.png]]
- 대상 서비스에서 일시적인 오류로 이벤트를 수신하지 못할때 전체 트랜잭션을 취소하기보다, **오류가 발생한 서비스만 재시도**하는게 적절함
- 모 서비스에서 생성한 이벤트는 아직 메시지 큐에 저장되어 있으므로 일시적인 오류가 해결되는 순간에 대상 서비스가 해당 메시지를 처리함
## 업무적인 이유로 전체 트랜잭션을 취소해야 할때
![[이벤트기반_트랜잭션_작업오류.png]]
1. 비즈니스 로직 상 의도적으로 WRITE 작업을 수행하지 않음
2. 대상 서비스에서 이벤트 발송
3. 모 서비스가 이벤트 수신
![[이벤트기반_트랜잭션_취소.png]]
4. 모 서비스에서 데이터 삭제(d2)
5. 트랜잭션의 상태를 취소 중으로 변경(d3)
6. 취소 이벤트 발송(d4)
7. 대상 서비스가 이벤트 수신(e1, f1)
8. WRITE 작업을 하지 않은 서비스는 데이터 삭제 실패(e2)
9. WRITE 작업을 한 서비스는 데이터 삭제(f2)
10. 데이터 삭제후 완료 이벤트 발송(f3)
11. 모 서비스에서 완료 이벤트 수신(d5)
12. 과정 생성 트랜잭션을 실패 상태로 변경(d6)
# 독립성의 보완
- 동시성 이슈는 기술적으로 발생할 수 있는 모든 부분을 차단하기보다는 실제 발생할 수 있는 가능성과 발생했을 때의 영향을 고려하여 적절하게 조치해야함
- 모든 사례를 엄격하게 차단하려면 개발 난도가 올라가고 시스템 성능이나 안정성도 저하될 수 있음
- 결제처럼 중요한 기능은 모든 사례를 엄격하게 차단해야함
## 동시성 이슈 종류
- **Dirty Reads**: 다른 트랜잭션에서 커밋하지 않은 데이터를 읽는 현상
	- 진행 중인 트랜잭션의 데이터를 읽을 수 있기 때문에 데이터 간 일관성이 없을 수 있고, 해당 트랜잭션이 롤백되는 경우 실제 존재하지 않는 데이터를 참조한게 된다.
- **Non-Repeatable Read**: 한 트랜잭션에서 같은 데이터를 여러 번 읽을 때 이전과 다른 값이 조회되는 현상
	- 데이터를 읽은 후에 다른 트랜잭션이 해당 데이터를 변경하면 다시 읽었을 때 변경된 데이터가 조회되어 같은 트랜잭션에서 하나의 데이터가 여러 값을 가지게 된다.
	- 여러 테이블의 데이터를 읽는 긴 트랜잭션에서 시작 시점에 읽은 데이터와 종료 시점에 읽은 데이터가 일치하지 않을 수 있다.
	- 자연스러운 동작일 수도 있지만 통계나 분석 쿼리처럼 많은 데이터를 순차적으로 읽는 경우에는 문제 될 수 있다.
- **Phantom Read**: 한 트랜잭션에서 쿼리를 수행한 후에 다시 같은 쿼리를 수행했을때 앞의 쿼리에 없었던 데이터가 두 번째 쿼리에 나타나는 현상
	- 첫 번째 쿼리의 결과를 전제 조건으로 쓰기 작업을 수행한다면, 실제 쓰는 시점에는 앞의 조건이 변경되어 결국 잘못된 쓰기가 발생할 수 있다.
## 데이터베이스의 일반적인 격리 수준
- Read Uncommitted: 커밋되지 않은 데이터를 조회할 수 있다.
- Read Committed: 커밋된 데이터만 조회할 수 있다.
- Repeatable Read: 한 트랜잭션 내에서는 다른 트랜잭션이 데이터를 변경하더라도 영향을 받지 않는다.
- Serializable: 트랜잭션이 순차적으로 실행되는 것과 동일하게 실행되어 모든 동시성 이슈를 방지한다.

| 격리 수준            | Dirty Read | Non-Repeatable Read | Phantom Read |
| ---------------- | ---------- | ------------------- | ------------ |
| Read Uncommitted | X          | X                   | X            |
| Read Committed   | O          | X                   | X            |
| Repeatable Read  | O          | O                   | △            |
| Serializable     | O          | O                   | O            |
|                  |            |                     |              |
- 대부분 Read Committed나 Repeatable Read 수준 사용
- Serializable은 성능 저하로 인해 실제 사용하는 경우는 드뭄
- 일반적으로 Non-Repeatable Read나 Phantom Read 이슈는 애플리케이션이 관리해야하고, DB는 동기화 도구(`SELECT FOR UPDATE`: 조회된 모든 데이터와 관련된 인덱스에 락을 걸ㅇㅓ 다른 트랜잭션이 수정하지 못하게 함)를 제공함
## MSA에서 달라지는 점
- 한 서비스 내에서 발생하는 동시성 이슈는 ACID 트랜잭션이 보장되므로 고려할 필요 없음
- MSA에서는 **여러 사용자가 ** 동시성 이슈가 발생할 수 있음
- 