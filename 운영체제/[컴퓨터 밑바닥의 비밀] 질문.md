---
Created: 2024-11-07
---
---
Created: 2024-11-07
---
# JVM안에 컴파일러가 포함되있는 것인가?
JIT 컴파일러와 AOT(Ahead-of-Time)컴파일러 (java 9부터)가 포함되어 있습니다.
AOT 컴파일러는 명시적으로 설정할때만 사용되며, spring native나 GraalVM Native Image를 빌드할때 사용됩니다.
# .java 파일은 어떻게 컴파일되고 JVM을 통해 실행되나?
운영체제 측면에서, JVM 자체는 운영체제의 일반 프로세스로 실행됩니다.
JVM이 사용하는 힙, 메서드 영역, 스택 등은 운영체제로부터 할당받은 메모리 영역에 배치됩니다.
다이렉트 메모리의 경우 종종 JVM 힙을 거치지 않고 운영체제의 메모리를 직접 사용하기도 합니다.
JVM 내부의 스레드는 대부분 운영체제의 네이티브 스레드에 1:1로 매핑됩니다.
실제 스레드 스케줄링은 대부분 운영체제의 스케줄러에 의해 관리됩니다.
JVM이 네이티브 메서드를 실행할때는 운영체제의 라이브러리나 기능을 직접 호출합니다.

.java 파일은 javac 컴파일러를 통해 바이트 코드(.class)로 변환됩니다. javac 컴파일러는 JVM에 포함되어있지 않고, JDK의 일부입니다. JVM 안에 JIT 컴파일러를 통해 바이트 코드가 기계 명령어로 변환됩니다.
1. 컴파일 단계(.java -> .class)
	- .java 파일이 Javac 같은 프런트엔드 컴파일러에 의해 처리됩니다.
	- Javac 컴파일러는 어휘분석, 구문분석을 거쳐 추상 구문 트리(AST)를 생성한 다음, 바이트 코드 명령어 스트림을 생성합니다.
	- Javac 컴파일러는 문법 검사를 수행하여 generic, auto-boxing/unboxing 같은 문법을 원래의 기본적인 문법 구조로 되돌립니다.
	- Javac 컴파일 결과물은 플랫폼에 독립적인 바이트코드이며, [[class 파일]] 형태로 저장됩니다.
	- Javac 컴파일 과정에는 Linking 단계가 없습니다. JVM이 .class 파일을 로드할때 Dynamic Linking이 발생합니다.
2. 실행 단계(.class by JVM)
	- 컴파일된 .class 파일은 JVM 위에서 실행됩니다.
	- JVM은 .class 파일을 실행하기 위해 클래스 로딩 서브시스템, 런타임 데이터 영역, 실행 엔진 등의구성 요소를 사용합니다.
	- 클래스 로딩
		- JVM이 특정 클래스가 필요할 때, 클래스 로더 서브시스템이 .class 파일을 메모리로 로드합니다.
		- 클래스 로딩은 로딩(loading), 검증(verification), 준비(preparation), 파싱/해석(resolution), 초기화(initialization)의 단계를 거칩니다.
			- 검증: 클래스 파일의 바이트코드가 유효하고 안전한지 확인하는 매우 중요한 단계이며, 시스템 보안에 필수적입니다.
			- 준비: 클래스 변수(static field)에 메모리를 할당하고 기본값을 설정합니다.
			- 해석: .class 파일의 상수 풀에 있는 심볼릭 참조를 메모리상의 직접 참조로 변환합니다.(dynamic linking)
			- 초기화: 클래스의 클래스 변수 초기화 코드와 static 블록을 실행합니다. 이는 new 키워로 인스턴스 생성, static 멤버 접근 등의 조건에 의해 트리거됩니다.
		- 일반적으로 부모 위임 모델(Parent Delegation Model)을 사용하여 클래스 로더 간의 우선순위를 정하고, java.lang.Object와 같은 핵심 클래스가 중복 로딩되지 않도록 보장합니다.
		- JDK 9부터는 **Java 모듈 시스템(JPMS)** 이 도입되어 클래스 로딩 아키텍처가 변경되었으며, **모듈 기반의 캡슐화/격리 메커니즘**이 지원됩니다.
	- JVM 런타임 데이터 영역 (JVM Runtime Data Areas)
		- JVM이 프로그램을 실행하면서 관리하는 메모리 영역들입니다.
		- 프로그램 카운터(Program Counter - PC): 스레드마다 독립적인 작은 메모리 공간으로, 현재 스레드가 실행할 바이트코드 명령어의 주소를 가리킵니다. 스레드 전환 후 올바른 위치로 돌아오는 데 사용됩니다. OutOfMemoryError가 발생하지 않는 유일한 영역입니다.
		- Java 가상 머신 스택(Java Virtual Machine Stack): 스레드마다 독립적이며, **스택 프레임(Stack Frame)** 을 저장합니다. 메서드가 호출될 때마다 스택 프레임이 스택에 쌓이고, 메서드 실행이 끝나면 스택에서 제거됩니다. 스택 프레임은 메서드의 지역 변수 테이블, 오퍼랜드 스택, 동적 연결 정보, 메서드 반환 주소 등을 포함합니다.
		- 네이티브 메서드 스택(Native Method Stack): Java 메서드가 아닌 네이티브 메서드 실행을 위해 사용되는 스택입니다.
		- Java 힙(Java Heap): 모든 스레드가 공유하는 메모리 영역으로, 대부분의 객체 인스턴스가 생성되는 공간입니다. **가비지 컬렉션(GC)** 의 주요 대상입니다.
		- 메서드 영역(Method Area): 모든 스레드가 공유하는 메모리 영역으로, **클래스 정보(클래스 구조, 상수 풀, 필드 및 메서드 정보 등)** 를 저장합니다. GC 대상이 될 수 있지만, 힙에 비해 효율이 낮습니다. (JDK 8부터 영구 세대(PermGen)가 메타스페이스(Metaspace)로 대체되었습니다)
		- 런타임 상수 풀(Runtime Constant Pool): 메서드 영역의 일부이며, 클래스 파일의 상수 풀이 런타임에 로드되어 저장됩니다. 메서드/필드의 심볼릭 참조 등이 여기에 있으며, 동적 연결 시 해석됩니다.
		- 다이렉트 메모리(Direct Memory): JVM 명세에 정의된 런타임 데이터 영역은 아니지만, NIO 사용 시 OS 메모리를 직접 할당하여 사용하며 OutOfMemoryError를 발생시킬 수 있습니다.
	- 실행 엔진 (Execution Engine)
		- 런타임 데이터 영역에 배치된 바이트코드 명령어를 실행하는 역할을 합니다20.
		- 일반적으로 **인터프리터(Interpreter)** 와 JIT(Just-In-Time) 컴파일러를 혼합하여 사용합니다.
		- 인터프리터는 바이트코드 명령어를 하나씩 읽어서 실행합니다. 개념적으로 스택 기반 명령어 집합으로 동작합니다.
		- JIT 컴파일러는 **Hot Spot(빈번하게 실행되는 코드)** 을 탐지하여, 해당 바이트코드를 실시간으로 네이티브 머신 코드로 컴파일합니다. JIT 컴파일은 백그라운드 스레드에서 진행됩니다.
		- JIT 컴파일된 네이티브 코드는 특정 운영체제 및 하드웨어에 최적화되며, 가상 메서드 인라인(Virtual Method Inlining)을 위한 CHA(Class Hierarchy Analysis), 스택 할당 및 동기화 제거를 위한 Escape Analysis 등 다양한 최적화 기법이 적용될 수 있습니다.
		- 일단 코드가 JIT 컴파일되면, JVM은 인터프리터 실행 대신 네이티브 코드를 실행하여 성능을 향상시킵니다.
		- 최근에는 AOT(Ahead-of-Time) 컴파일 방식도 주목받고 있습니다. Jaotc와 같은 도구는 프로그램 실행 전에 바이트코드를 네이티브 라이브러리로 미리 컴파일하여 시작 시간 단축 및 준비 시간 감소를 목표로 합니다. Graal VM의 Substrate VM은 더 나아가 JVM 없이 실행되는 네이티브 실행 파일을 생성하는 데 중점을 둡니다.

# 링커의 symbol resolution(해석)단계에서, 어떻게 여러 object file(대상 파일)들에서 동일한 유형의 영역끼리 합칠 수 있는가?
링커가 여러 object file에서 동일한 유형의 영역을 합치는 과정:
1. object file 구조 이해
	- 텍스트 세그먼트 (Text segment): 기계어 코드를 포함합니다. 다른 파일에 대한 미해결 참조 때문에 실행 불가능할 수 있습니다.
	- 데이터 세그먼트 (Data segment): 프로그램의 데이터(예: 전역 변수)의 이진 표현을 포함합니다. 이 데이터 또한 다른 파일에 대한 미해결 참조 때문에 불완전할 수 있습니다.
	- 재배치 정보 (Relocation information): 프로그램이 메모리에 로드될 때 변경되어야 하는 절대 주소에 의존하는 명령어 및 데이터 단어를 식별합니다. 어셈블러는 각 파일을 독립적으로 어셈블하므로, 최종 메모리 위치를 알지 못하기 때문에 이 정보가 필요합니다.
	- 심볼 테이블 (Symbol table): 해당 파일에 정의된 레이블의 이름과 주소를 연결하고, 미해결 참조(다른 파일에 정의된 외부 레이블) 목록을 포함합니다.

2. 메모리 배치 계획 (Symbolically place code and data modules)
	- 링커는 먼저 입력받은 모든 오브젝트 파일과 라이브러리에서 코드와 데이터를 가져와 실행 파일에서 차지할 메모리 레이아웃을 계획합니다.
	- 링커가 각 모듈이 차지할 메모리 위치를 결정하고, 실행 파일에 코드와 데이터를 복사하는 과정을 통해 논리적으로 모든 오브젝트 파일의 텍스트 세그먼트를 모아서 실행 파일의 텍스트 세그먼트 영역에 배치하고, 데이터 세그먼트를 모아서 실행 파일의 데이터 세그먼트 영역에 배치함을 유추할 수 있습니다. MIPS 시스템의 소프트웨어 규칙에 따른 메모리 배치(코드 영역, 데이터 영역 등)가 예시입니다.
3. 주소 결정 (Determine the addresses of data and instruction labels)
	- 링커는 계획된 메모리 레이아웃에 따라 프로그램 전체에서 모든 레이블(코드 레이블, 데이터 레이블)의 최종 절대 메모리 주소를 결정합니다.
	- 여기에는 오브젝트 파일 내에서 정의된 지역 레이블뿐만 아니라 다른 파일에서 참조된 외부 레이블의 실제 주소도 포함됩니다.
4. 참조 수정 (Patch references)
	- 심볼 테이블과 재배치 정보를 사용하여, 링커는 각 오브젝트 파일의 코드와 데이터 내에서 **미해결된 참조(주소)** 를 찾습니다. 그리고 3단계에서 결정된 최종 주소를 사용하여 해당 참조를 수정합니다. 예를 들어:
		- 다른 프로시저를 호출하는 jal 명령어의 주소 필드는 호출될 프로시저의 최종 주소로 업데이트됩니다.
		- 전역 변수를 로드(lw)하거나 저장(sw)하는 명령어의 주소 필드(오프셋)는 해당 변수의 최종 메모리 위치(예: 전역 포인터 레지스터($gp) 기준 오프셋)로 업데이트됩니다.

이러한 과정을 통해 링커는 여러 오브젝트 파일의 코드와 데이터를 결합하고, 파일 간의 참조를 해결하여 완전한 실행 파일을 생성합니다. 생성된 실행 파일은 미해결 참조나 (일반적으로) 재배치 정보가 포함되지 않은 형태로 로더에 의해 메모리에 로드되어 실행 준비가 됩니다.

# Node.js는 싱글 스레드인데 어떻게 비동기 호출이 가능한가?
Node.js는 싱글 스레드(Event Loop)로 동작하지만, 실제로는 내부적으로 다음과 같은 구성요소들이 함께 작동합니다:
- Event Loop (메인 스레드)
- Worker Threads Pool (libuv 라이브러리)
- Thread Pool (백그라운드 작업용)
비동기 작업이 처리되는 과정:
```
파일 읽기 요청 → Event Loop가 요청 수신 
→ Worker Thread에 작업 위임 
→ Event Loop는 다른 작업 처리 
→ 파일 읽기 완료 시 Callback 실행
```
 - Event Loop가 Non-blocking I/O 작업들을 Worker Threads에 분배
 - CPU 집약적 작업은 Thread Pool을 활용
 - libuv 라이브러리가 운영체제 수준의 비동기 작업 처리 
# 코루틴이 일시중지되어도 worker 스레드가 블로킹되지 않는 이유는?
코루틴을 위해 특별히 설계된 **비동기 함수**가 호출되야 worker 스레드가 블로킹되지 않습니다.
- **OS 레벨의 블로킹 함수 (e.g., `time.sleep`, 일반적인 `file.read`)**: 이 함수들은 호출 시 해당 스레드 전체를 멈추게 합니다. 코루틴 내에서 이런 함수를 호출하면 코루틴의 장점을 전혀 살릴 수 없습니다.
- **코루틴을 지원하는 논블로킹(Non-blocking) 함수 (e.g., `asyncio.sleep`, `aiohttp.get`)**: 이 함수들은 실제로는 스레드를 블로킹하지 않습니다. I/O 작업을 이벤트 루프에 등록하고, 즉시 CPU 제어권을 다른 코루틴에 양보(yield)합니다.
1. 실행과 일시 중지 (Suspend)
    - 하나의 스레드(Worker Thread)에서 **이벤트 루프(Event Loop)** 가 실행됩니다. 이벤트 루프는 코루틴들의 실행을 스케줄링하는 주체입니다.
    - 하나의 코루틴(`Coroutine A`)이 실행되다가 `await` 키워드를 만나 비동기 I/O 작업(e.g., 네트워크 요청, DB 조회)을 호출합니다.
    - 이 비동기 함수는 실제 작업을 운영체제의 이벤트 통지 시스템(`epoll`, `kqueue`, `IOCP` 등)에 등록하고, 즉시 제어권을 이벤트 루프에게 **반환**합니다. 이 시점에서 `Coroutine A`는 **일시 중지(suspended)** 상태가 됩니다.    
2. 스케줄링과 다른 코루틴 실행
    - `Coroutine A`가 멈춘 동안, 스레드는 전혀 멈추지(blocking) 않았습니다.
    - 이벤트 루프는 CPU 제어권을 되찾아, 현재 실행 가능한(ready) 상태에 있는 다른 코루틴(`Coroutine B`)을 찾아 실행을 시작하거나 재개합니다. 이를 **컨텍스트 스위칭(Context Switching)** 이라고 부르지만, 스레드 간의 컨텍스트 스위칭보다 훨씬 가볍고 빠릅니다.
3. 작업 완료와 재개 (Resume)
    - `Coroutine A`가 요청했던 I/O 작업이 완료되면, 운영체제는 이벤트 루프에게 이 사실을 알려줍니다.    
    - 이벤트 루프는 작업 결과를 받아 `Coroutine A`를 **준비(ready)** 상태로 변경합니다.
    - 자신의 차례가 돌아오면, 이벤트 루프는 `Coroutine A`가 멈췄던 바로 그 `await` 지점 다음부터 실행을 **재개(resume)** 시키며, I/O 작업의 결과값을 반환해 줍니다.

이 모든 과정이 **단일 스레드** 또는 정해진 수의 스레드 풀 내에서 일어나므로, 스레드를 새로 생성하는 비용 없이 수많은 I/O 작업을 동시에 처리하는 효과를 낼 수 있습니다. "사용자 서비스"는 운영체제가 제공하는 이러한 I/O 완료 통지 메커니즘을 지칭하는 것으로 이해할 수 있습니다.

# 코루틴 간 컨텍스트 스위칭이 스레드 간 컨텍스트 스위칭보다 가볍고 빠른 이유
그 이유는 **제어 주체**와 **저장해야 할 정보의 양**에서 결정적인 차이가 나기 때문입니다.
- 스레드 컨텍스트 스위칭은 **운영체제 커널(OS Kernel)** 의 개입이 필요한 무겁고 강제적인(선점형 멀티태스킹) 작업입니다.
- **코루틴 컨텍스트 스위칭**은 **애플리케이션(User Space)** 내에서 프로그래머의 코드에 의해 자발적으로(협력적 멀티태스킹) 일어나는 가벼운 작업입니다.
### 스레드 컨텍스트 스위칭
1. **커널 모드 전환 (Mode Switch)**: 스위칭을 위해 반드시 **유저 모드(User Mode)에서 커널 모드(Kernel Mode)로** 전환되어야 합니다. 이 과정 자체에 상당한 CPU 사이클이 소모됩니다.
2. **전체 문맥 저장 (Heavy Context)**: 커널은 스레드를 언제 어디서든 다시 완벽하게 복구할 수 있도록 스레드와 관련된 모든 상태를 저장해야 합니다.
	- CPU 레지스터: Instruction Pointer(다음에 실행할 명령어 주소), Stack Pointer 등 모든 범용/특수 레지스터 값
	- 메모리 정보: 해당 스레드의 가상 메모리 매핑 정보(페이지 테이블 등)
	- OS 관련 정보: 스레드 상태, 스케줄링 우선순위, 열어둔 파일 핸들 등 커널이 관리하는 각종 데이터
3. **CPU 캐시 비효율성**: 스레드가 바뀌면, 이전에 실행되던 스레드 A가 사용하던 데이터가 담긴 CPU 캐시가 쓸모없어집니다(Cache flush). 새로 실행되는 스레드 B는 필요한 데이터를 다시 메모리에서 읽어와야 하므로 **캐시 미스(Cache Miss)** 가 발생하여 성능 저하를 유발합니다.
4. **스케줄러 실행**: 커널 내 스케줄링 알고리즘이 다음에 어떤 스레드를 실행할지 결정하는 연산도 추가적인 비용입니다.

이 모든 과정은 **운영체제의 깊은 개입**을 필요로 하므로 수천~수만 CPU 사이클이 소모되는 비싼 작업입니다.
### 코루틴 컨텍스트 스위칭
코루틴은 **하나의 스레드 안에서** 실행되며, `await` 이나 `yield` 같은 키워드를 만났을 때 **자발적으로** 제어권을 다른 코루틴에 넘깁니다.
1. **커널 모드 전환 없음**: 모든 과정이 유저 모드에서 일어나므로 커널의 개입이 전혀 필요 없습니다. 이는 단순한 **함수 호출(function call)**과 유사한 비용만 발생시킵니다.
2. **최소 문맥 저장 (Light Context)**: 코루틴은 자신이 멈춘 지점(`await` 다음)만 기억하면 되므로 최소한의 정보만 저장합니다.
    - CPU 레지스터: 다음에 실행할 명령어 주소(Instruction Pointer)와 스택 관련 레지스터 몇 개 정도만 저장하면 충분합니다.
    - 그 외 OS가 관리하는 복잡한 상태는 저장할 필요가 없습니다. 왜냐하면 어차피 같은 스레드 내에서 실행되기 때문입니다.
3. **CPU 캐시 효율성**: 같은 스레드 내에서 다른 코루틴으로 전환되므로, 앞서 실행된 코루틴이 사용하던 데이터가 CPU 캐시에 남아있을 확률이 높습니다(**캐시 친화적, Cache-friendly**). 이는 데이터 지역성(Locality of reference)을 높여 성능에 큰 이점을 줍니다.
4. **단순한 스케줄링**: 다음에 실행할 코루틴은 복잡한 OS 스케줄러가 아닌, 언어 런타임이나 라이브러리에 내장된 간단한 **이벤트 루프**에 의해 결정됩니다.
### TODO:
- User Mode vs. Kernel Mode
- System Call
- Stackful vs. Stackless Coroutines
- CPU의 메모리 접근 시 Locality of Reference

# 클로저
- 클로저는 코드와 데이터를 한데 묶어 변수로 사용하는 것입니다. 즉, 함수와 그 함수가 선언될 당시의 렉시컬 환경(Lexical Environment)의 조합입니다. 객체가 메서드(코드)와 속성(데이터)을 묶는 것과 유사한 개념입니다. 따라서 함수 반환여부와 관계없이, 내부 함수가 외부 함수의 변수를 참조(또는 캡처)하면 클로저입니다.
- 클로저는 함수가 자신이 생성된 환경을 기억하는 것입니다. 외부 함수의 실행이 끝나서 그 실행 컨텍스트(스택 프레임)가 사라진 후에도, 내부 함수는 자신이 생성되었던 환경(스코프)의 변수들에 계속 접근할 수 있습니다. 그래서 garbage collector는 해당 변수들을 메모리에서 제거하지 않습니다.
### TODO
- First-Class Functions: 함수를 변수에 할당하거나, 다른 함수에 인자로 전달하거나, 함수에서 반환할 수 있는 특성입니다. 클로저가 유용하게 사용되기 위한 전제 조건입니다.
- Lexical Scope vs Dynamic Scope: 클로저는 코드가 작성된 위치에 따라 변수의 유효 범위가 결정되는 렉시컬 스코프 때문에 가능합니다.
- Currying & Higher-Order Functions: 클로저는 함수형 프로그래밍에서 인자를 나누어 받는 커링이나, 함수를 다루는 고차 함수를 구현하는 핵심적인 기술로 사용됩니다.
# 함수 호출 시 매개변수를 레지스터에 할당할지, 스택에 저장할지를 결정하는 주체가 누구이며, 그 판단은 언제 어떻게 이루어지는가?
해당 결정은 운영체제가 아니라 **컴파일러(Compiler)**가 **호출 규약(Calling Convention)** 에 따라 내립니다. 프로그램이 기계어로 번역되는 컴파일 시점에 **컴파일러**가 아키텍처와 운영체제에 따라 정해진 규칙인 **호출 규약(Calling Convention)** 을 기계적으로 따를 뿐입니다. 운영체제는 이 과정에 전혀 관여하지 않습니다.
함수의 매개변수가 너무 많아 모두 레지스터에 저장할 수 없다는 사실을 운영체제가 알 수 있는 이유
함수의 매개변수, 지역변수가 레지스터 수보다 많으면 일부 매개변수가 스택 프레임에 저장됩니다.
1. **호출 규약(Calling Convention)**: 함수를 호출하는 쪽(Caller)과 호출되는 쪽(Callee) 사이의 **약속 또는 규칙**입니다. 이 규칙은 특정 CPU 아키텍처와 운영체제가 결합하여 정의되며(이를 합쳐 **ABI, Application Binary Interface**라고도 합니다), 다음과 같은 내용을 명시합니다.
    - 함수의 매개변수를 어떤 순서로, 어디에 담아 전달할 것인가? (예: 첫 4개는 레지스터, 나머지는 스택)
    - 어떤 레지스터를 사용할 것인가? (예: `RDI`, `RSI`, `RDX` 순서로 사용)
    - 함수의 반환 값은 어디에 담아서 돌려줄 것인가? (예: `RAX` 레지스터)
    - 함수 호출 전후에 스택 포인터는 누가 정리할 것인가? (Caller or Callee)
        
2. 컴파일러의 역할: 프로그래머가 함수 호출 코드를 작성하면(`my_func(a, b, c, d, e)`), 컴파일러는 해당 플랫폼의 호출 규약을 확인합니다.
    예를 들어, 64비트 리눅스에서 사용하는 `System V AMD64 ABI` 호출 규약은 다음과 같이 정해져 있습니다.
    > "정수 및 포인터 타입 매개변수는 **최대 6개**까지 레지스터(`RDI`, `RSI`, `RDX`, `RCX`, `R8`, `R9`)를 통해 전달하고, **7번째 매개변수부터는 스택**을 통해 전달한다."
    
    컴파일러는 이 규칙을 보고 기계어 코드를 생성합니다. 만약 매개변수가 8개라면, 컴파일러는 고민 없이 앞 6개는 레지스터에 값을 넣는 코드를, 뒤 2개는 스택에 쌓는 코드를 만들어냅니다. 운영체제가 "레지스터가 부족하다"라고 알려주는 것이 아니라, 컴파일러는 이미 정해진 규칙을 따를 뿐입니다.
    
3. 운영체제의 역할: 운영체제는 이렇게 컴파일된 프로그램(실행 파일)을 메모리에 올리고 실행을 시작시켜주는 역할을 합니다. 프로그램이 실행되는 동안 개별적인 함수 호출 규칙에는 관여하지 않습니다. 단, 프로그램이 운영체제의 기능(e.g., 파일 열기)을 사용하기 위해 시스템 콜(System Call)을 할 때는, 해당 시스템 콜에 맞는 별도의 호출 규약이 사용됩니다.
### TODO
- 호출 규약 (Calling Convention): `cdecl`, `stdcall`, `fastcall` 등 다양한 종류가 있으며, 아키텍처와 운영체제에 따라 다릅니다. 이 규약이 맞지 않으면 프로그램이 오작동하거나 충돌합니다.
- ABI (Application Binary Interface): 호출 규약을 포함하는 더 큰 개념으로, 컴파일된 코드 조각들이 서로 소통하는 방법에 대한 모든 규칙을 정의합니다. 라이브러리와 애플리케이션이 호환되려면 ABI가 맞아야 합니다.
# 프로세스 주소 공간의 스택프레임의 증감 구현 방법과 구현 주체
스택 프레임의 증감은 **CPU의 스택 포인터(Stack Pointer) 레지스터를 조작**하여 구현되며, 이 구현의 주된 책임은 **컴파일러**에게 있습니다.
스택 프레임의 증가와 감소는 CPU의 특수 목적 레지스터인 **스택 포인터(SP, x86-64에서는 `RSP`)** 와 **베이스 포인터(BP, x86-64에서는 `RBP`)** 를 이용해 매우 효율적으로 구현됩니다. 대부분의 아키텍처에서 스택은 높은 메모리 주소에서 낮은 주소 방향으로 자랍니다.
### 스택 프레임의 증가 (함수 호출 시)
새로운 함수가 호출되면, 그 함수가 사용할 자신만의 작업 공간, 즉 스택 프레임이 기존 스택의 "아래"에 생성됩니다. 이 과정은 **함수 프롤로그(Function Prologue)** 라고 불리는 정형화된 기계어 코드에 의해 수행됩니다.
1. **인자 전달**: 함수를 호출하는 쪽(Caller)에서 필요시 인자를 스택에 넣습니다. (`push` 명령어)
2. **복귀 주소 저장**: `call` 명령어가 실행되면, CPU는 함수 실행이 끝난 뒤 돌아올 위치(복귀 주소)를 스택에 자동으로 저장합니다.
3. **이전 프레임 포인터 저장**: 새로 호출된 함수(Callee)는 이전 함수의 스택 프레임 위치를 기억하기 위해 현재 `RBP` 값을 스택에 저장합니다. (`push rbp`)
4. **새 프레임 포인터 설정**: 현재 `RSP` 위치를 새로운 프레임의 기준점(`RBP`)으로 삼습니다. (`mov rbp, rsp`)
5. **지역 변수 공간 확보**: 함수의 지역 변수들이 사용할 공간만큼 `RSP` 값을 아래로 내립니다. 즉, **`RSP`에서 특정 값을 빼서 스택을 증가시킵니다.** (`sub rsp, <지역 변수 크기>`)
### 스택 프레임의 감소 (함수 반환 시)
함수가 자신의 역할을 마치고 반환될 때, 생성했던 스택 프레임을 정리하고 이전 프레임으로 복귀합니다. 이 과정은 **함수 에필로그(Function Epilogue)** 코드에 의해 수행됩니다.
1. **지역 변수 공간 해제**: `RSP`를 현재 `RBP` 위치로 되돌려 지역 변수 공간을 한 번에 해제합니다. (`mov rsp, rbp` 또는 `leave` 명령어)
2. **이전 프레임 포인터 복원**: 함수 시작 시 저장해두었던 이전 `RBP` 값을 스택에서 꺼내 복원합니다. (`pop rbp`)
3. **복귀 주소로 점프**: `ret` 명령어가 실행되면, CPU는 스택의 가장 위에 있는 복귀 주소를 꺼내 해당 위치로 프로그램 실행 흐름을 옮깁니다.

이처럼 스택 프레임의 생성과 소멸은 단순히 **`RSP` 레지스터의 값을 더하고 빼는 산술 연산**으로 이루어지므로 매우 빠릅니다.

### 스택 프레임 구현 주체
스택 프레임과 그 증감을 구현하는 책임은 여러 주체에게 나뉘어 있지만, 핵심적인 역할은 **컴파일러**가 담당합니다.
1. 컴파일러 - 설계자
	**가장 핵심적인 책임자**입니다. 프로그래머가 작성한 고급 언어 코드(C, C++, Rust 등)를 기계어로 번역할 때, **호출 규약(Calling Convention, ABI)** 에 맞춰 위에서 설명한 함수 프롤로그와 에필로그 코드를 자동으로 생성합니다. 즉, `sub rsp`, `push rbp`, `mov rsp, rbp`, `pop rbp` 같은 저수준 명령어를 만들어내는 주체입니다. 프로그래머는 스택을 직접 조작하지 않고 함수를 작성하기만 하면 됩니다.
2. CPU - 실행자
	컴파일러가 만든 기계어 명령을 **실제로 수행**하는 주체입니다. `RSP`, `RBP` 같은 레지스터를 내장하고 있으며, `push`, `pop`, `call`, `ret` 같은 스택 관련 명령어를 해석하고 실행하여 메모리와 레지스터 상태를 직접 변경합니다.
3. 운영체제 - 공간 할당자
	운영체제는 **개별 스택 프레임을 관리하지 않습니다.** 대신 프로세스가 처음 시작될 때, **스택이라는 메모리 영역 전체를 할당**하고 그 시작 주소를 CPU에 알려주는 역할을 합니다. 만약 프로그램 실행 중 스택이 할당된 영역을 넘어서려고 하면(Stack Overflow 직전), 페이지 폴트(Page Fault)를 통해 이를 감지하고 스택 영역을 추가로 확장해주는 역할을 하기도 합니다.
4. 프로그래머- 사용자
	프로그래머의 책임은 간접적입니다. 함수를 정의하고 지역 변수를 선언함으로써 **필요한 스택 프레임의 크기를 결정**하지만, 프레임을 할당하고 해제하는 구체적인 기계어 코드를 직접 작성하지는 않습니다. 즉, 컴파일러가 스택 프레임을 잘 만들도록 "요구"하는 역할을 합니다.
### TODO
- 운영체제의 Page Fault
# 프로세스 주소 공간의 힙 영역에서 메모리 조각의 헤더 크기
헤더의 크기는 다음과 같은 요인에 따라 결정됩니다
1. **CPU 아키텍처**: 32비트(x86) 시스템에서는 주소(포인터)의 크기가 4바이트지만, 헤더에는 보통 포인터 정보가 포함되므로 64비트 시스템에서는 최소 8바이트 이상이 필요합니다.
2. **메모리 할당자(Memory Allocator) 구현**: 어떤 할당자(`glibc`의 `ptmalloc`, `jemalloc`, `tcmalloc` 등)를 사용하느냐에 따라 헤더의 구조와 크기가 달라집니다. 대부분의 현대 할당자는 효율적인 관리를 위해 크기 정보와 가용 리스트(free list)를 위한 포인터를 모두 포함하므로, 64비트 시스템에서는 **16바이트 또는 24바이트**가 일반적입니다.
3. **데이터 정렬(Data Alignment)**: 성능상의 이유로 CPU는 특정 배수(예: 8바이트 또는 16바이트)의 주소에 접근할 때 가장 효율적입니다. 메모리 할당자는 이 정렬 요구사항을 맞추기 위해 헤더와 사용자 데이터 영역 전체의 크기를 조정하며, 이 과정에서 헤더의 크기도 영향을 받습니다.
결론적으로, 4바이트는 32비트 시스템의 매우 단순한 할당자에서나 가능한 크기이며, 오늘날의 64비트 환경에서는 너무 작아서 필요한 정보를 담을 수 없습니다.
# 힙 영역에서 메모리 조각의 헤더에 들어있는 것
힙 메모리 조각의 헤더는 **메모리 할당자**가 해당 조각을 관리하기 위한 **메타데이터(metadata)** 를 담고 있습니다. 마치 도서관의 책에 붙어있는 도서 정보 스티커와 같습니다. 핵심적인 정보는 다음과 같습니다.
1. **블록 크기 (Block Size)**
	- 가장 필수적인 정보입니다. 할당자는 `free()` 함수 호출 시 포인터(주소)만 받고 크기 정보는 받지 않습니다. 이때 할당자는 포인터의 바로 앞을 조회하여 헤더에 기록된 블록 크기를 읽고, 정확히 얼마만큼의 메모리를 해제해야 하는지 파악합니다.
2. **상태 플래그 (Status Flags)**
	- 해당 블록이 현재 **사용 중(allocated)인지 아니면 해제되어 사용 가능한 상태(free)인지**를 나타내는 플래그입니다.
	- 이 정보는 공간을 절약하기 위해 보통 블록 크기 정보의 마지막 몇 비트(bit)에 함께 저장됩니다. 예를 들어, 메모리 주소는 항상 8의 배수로 정렬되므로 마지막 3비트는 항상 0입니다. 할당자는 이 비트들을 상태 플래그로 활용합니다.
3. **가용 리스트 포인터 (Free List Pointers)**
	- 만약 해당 블록이 **사용 가능한 상태(free)라면**, 할당자는 이 블록을 다른 가용 블록들과 연결하여 **가용 리스트(free list)**라는 연결 리스트(linked list)로 관리합니다.
	- 이때 헤더(또는 해제된 데이터 영역)에는 이전 가용 블록을 가리키는 포인터(**`prev`**)와 다음 가용 블록을 가리키는 포인터(**`next`**)가 저장됩니다. 이를 통해 할당자는 새로운 메모리 할당 요청이 왔을 때 가용 리스트를 빠르게 탐색하여 적절한 크기의 블록을 찾을 수 있습니다.
일부 할당자는 메모리 블록의 끝에 **풋터(footer)** 또는 **경계 태그(boundary tag)** 를 두어 헤더 정보(주로 크기)의 복사본을 저장하기도 합니다. 이는 인접한 블록과 병합(coalescing) 작업을 할 때 효율성을 높여줍니다.
# 할당된 메모리 조각에 발생하는 내부 단편화(fragmentation)
실제 요청된 크기보다 더 큰 메모리 조각을 할당하여 남는 부분이 낭비되는 현상입니다.
**데이터 정렬(Data Alignment)** 규칙을 적용하는 상황을 가정해보겠습니다. 대부분의 시스템에서 메모리 할당은 성능을 위해 8바이트 또는 16바이트 배수로 이루어집니다.
1. 할당 요청: 12바이트를 요청합니다.
2. 규칙 적용: 메모리 할당자는 16바이트 정렬 규칙에 따라 12바이트보다 큰 가장 가까운 16의 배수인 **16바이트를 할당**합니다.
3. **내부 단편화 발생**:
    - 프로그램은 16바이트를 할당받았지만, 실제로는 12바이트만 사용합니다.
    - 이때 할당된 조각 내부에 남는 **`16 - 12 = 4`바이트**의 공간이 바로 **내부 단편화**입니다.
    - 이 4바이트는 해당 메모리 조각이 해제되기 전까지는 그 누구도 사용할 수 없는 낭비되는 공간입니다.
# Segmentation Fault
**프로그램이 자신의 주소 공간 내에서 허용되지 않은 메모리 영역에 접근하려고 시도할 때 운영체제가 해당 프로그램을 강제 종료시키는 과정**에서 발생하는 오류입니다. 주된 원인은 다음과 같습니다.
- NULL 포인터를 역참조하는 경우
- 배열의 허용된 범위를 벗어나 접근하는 경우
- 읽기 전용 메모리 영역에 쓰려고 하는 경우 (e.g., 코드 영역)

운영체제 커널이 사용자 프로그램으로부터 안전하게 보호되는 이유는 소프트웨어가 아닌 **CPU 하드웨어의 보호 메커니즘** 덕분입니다.
1. **보호 링 (Protection Rings)**: 최신 CPU는 권한 수준을 여러 단계(Ring 0 ~ Ring 3)로 나눕니다.
	- **커널 모드 (Ring 0)**: 운영체제 코드가 실행되는 모드로, 모든 하드웨어에 접근할 수 있는 **최고 권한**을 가집니다.
	- **사용자 모드 (Ring 3)**: 일반 애플리케이션이 실행되는 모드로, **제한된 권한**만 가집니다. 중요한 작업(I/O, 메모리 할당 등)은 반드시 커널에 시스템 콜(System Call)을 통해 요청해야 합니다.
2. **메모리 관리 장치 (MMU)**: CPU 내의 하드웨어인 MMU는 사용자 프로그램이 메모리에 접근할 때마다 해당 주소가 유효한지, 그리고 접근 권한이 있는지를 실시간으로 검사합니다.
	- 사용자 프로그램이 커널의 메모리 주소를 침범하려고 하면, MMU는 이를 **권한 위반**으로 감지하고 즉시 CPU에 하드웨어 예외(exception)를 발생시킵니다.
	- 이 예외 신호는 실행 흐름을 사용자 모드에서 커널 모드로 강제 전환시키고, 커널 내의 예외 처리 루틴을 실행시킵니다.
	- 커널은 오류를 일으킨 프로그램에 **"너는 규칙을 위반했어"** 라는 의미로 `SIGSEGV` (Segmentation Violation) 신호를 보내고, 해당 프로그램은 대부분 종료됩니다.
Segmentation Fault는 **사용자 프로그램의 잘못된 메모리 접근 시도**이며, 이는 커널을 파괴하는 오류가 아니라 **커널의 보호 메커니즘이 성공적으로 작동하여 스스로를 지키고 오류가 발생한 프로그램을 종료시켰다는 증거**입니다.
# CPU Protection Ring의 결정 주체와 동작 방식
CPU 보호 링은 CPU 제조사가 **하드웨어에 구현한 기능**이며, **운영체제(OS)는 이 하드웨어 기능을 활용**하여 시스템을 관리하는 주체입니다. 즉, 어느 한쪽이 단독으로 결정하는 것이 아닌, 하드웨어와 소프트웨어의 명확한 역할 분담으로 결정되고 운영됩니다.

CPU는 보호 링이라는 **개념을 물리적으로 설계하고 규칙 위반을 감시**하는 역할을 합니다.
- **기능 내장**: CPU 제조사(Intel, AMD 등)는 칩을 설계할 때부터 여러 개의 권한 레벨(Privilege Level), 즉 보호 링(x86 기준 4개, Ring 0~3)을 **하드웨어 자체에 내장**합니다. 이는 프로그램으로 결정되는 것이 아닌, CPU의 아키텍처에 각인된 것입니다.
- **현재 상태 기록**: CPU는 현재 실행 중인 코드의 권한 레벨(CPL, Current Privilege Level)을 **`CS`와 같은 특수 목적 레지스터에 항상 기록**하고 있습니다.
- **규칙 강제 집행**: CPU는 낮은 권한의 링(e.g., Ring 3)에서 실행 중인 코드가 높은 권한 링(e.g., Ring 0)에서만 허용되는 **특권 명령(Privileged Instruction)** 을 실행하려고 하면, 이를 **하드웨어 수준에서 즉시 차단하고 예외(Exception)를 발생**시킵니다.

운영체제는 CPU가 제공하는 보호 링이라는 **기능을 사용하여 시스템의 안정성과 보안을 실현**하는 역할을 합니다.
- **링 할당**: 부팅 과정에서 운영체제 커널은 자신을 가장 높은 권한인 **Ring 0**에 배치합니다. 그리고 사용자 애플리케이션을 실행할 때는 가장 낮은 권한인 **Ring 3**를 할당합니다.    
- **링 전환 관리**: 운영체제는 사용자 프로그램이 합법적으로 커널의 기능을 요청할 수 있는 유일한 통로인 **시스템 콜(System Call)** 인터페이스를 제공합니다. 사용자 프로그램이 시스템 콜을 호출하면, **CPU는 이를 감지하여 안전하게 Ring 3에서 Ring 0로 전환**해주고, 커널 코드 실행이 끝나면 다시 Ring 3로 복귀시킵니다.

실제 동작 방식은 다음과 같은 흐름으로 이루어집니다.
1. 초기 설정: 컴퓨터가 켜지면 OS 커널이 메모리에 로드되고, CPU를 Ring 0 상태로 설정하여 완전한 제어권을 가집니다.
2. 프로그램 실행: 사용자가 웹 브라우저 같은 프로그램을 실행하면, OS는 해당 프로그램을 위해 메모리 공간을 할당하고 CPU를 Ring 3 상태로 전환시킨 뒤 프로그램 코드를 실행시킵니다.
3. 특권 작업 요청: 브라우저가 파일을 저장해야 합니다. 이는 디스크에 접근해야 하는 특권 작업이므로 Ring 3에서는 직접 수행할 수 없습니다. 브라우저는 OS에 "파일 저장"을 요청하는 시스템 콜을 보냅니다.
4. 모드 전환 (하드웨어 역할): `SYSCALL` 명령어를 CPU가 받으면, CPU는 하드웨어적으로 실행 모드를 Ring 3에서 Ring 0로 전환하고, OS가 미리 지정해둔 시스템 콜 처리 루틴으로 점프합니다.
5. 커널 작업 수행: Ring 0 상태가 된 커널은 요청을 받아 파일 저장 작업을 안전하게 처리합니다.
6. 모드 복귀 (하드웨어 역할): 작업이 끝나면 커널은 `SYSRET` 같은 명령어를 실행합니다. CPU는 다시 실행 모드를 Ring 3로 되돌리고, 원래 프로그램이 멈췄던 지점으로 돌아가 실행을 재개합니다.

이처럼 보호 링은 **CPU가 제공하는 하드웨어 기반의 울타리**이며, **운영체제는 그 울타리 안에서 누가 어디에 머물고 어떻게 문을 통과할지를 관리**하는 정교한 협업 시스템입니다.

# 스레드 개수가 고정되있을때 CPU 코어 개수에 따른 성능 영향
운영체제(OS)의 관점에서 볼 때, **N개의 코어를 가진 멀티코어 프로세서는 OS에게 N개의 표준 CPU처럼 보입니다**. OS는 **CPU 스케줄러**를 통해 실행 가능한 스레드를 선택하여 사용 가능한 코어에 할당함으로써 병렬 실행을 가능하게 합니다.
## 코어 증가가 성능에 미치는 긍정적인 영향
사용자 스레드의 개수(T)가 고정되어 있고, 코어의 개수(P)가 T보다 많거나 같다고 가정할 때 (T≤P):

• **경쟁 최소화 및 응답 시간 개선:** 코어 수가 증가하면, 각 스레드가 전적으로 전용 코어에서 실행될 가능성이 높아지거나, 코어 간 자원 공유 및 **문맥 교환(Context Switch)** 필요성이 감소합니다. 이는 프로그램의 응답 시간을 개선하는 데 도움이 될 수 있습니다.

• **스케줄링 효율성 증대:** OS는 **멀티프로그래밍**을 통해 CPU 활용률을 최대화하는 것을 목표로 하며, 코어가 많을수록 실행 가능한 상태(Ready queue)에 있는 프로세스/스레드에게 항상 실행할 코어를 제공하여 CPU 활용률을 높일 수 있습니다.
## 성능 향상을 저해하는 주요 제한 요소
### 병렬성 자체의 한계 (Amdahl의 법칙)
프로그램의 성능 개선은 병렬화할 수 없는 **순차적인(sequential) 부분**의 비율에 의해 궁극적으로 제한됩니다. 아무리 코어 수를 늘려도, 이미 정해진 개수의 스레드 내에 순차적으로 실행되어야 하는 부분이 있다면, 전체 프로그램 실행 시간은 그 순차 부분에 의해 지배됩니다.
### 부하 불균형 (Load Imbalance)
성능을 개선하기 위해서는 **부하 분산(Load Balancing)** 이 중요합니다. 코어 수가 아무리 많아도, 만약 고정된 수의 스레드가 코어 사이에 균등하게 분배되지 않고 일부 코어에 작업이 집중된다면, 성능 향상 폭은 크게 떨어집니다. 예를 들어, 하나의 프로세서가 다른 프로세서보다 두 배의 부하를 가지면 속도 향상 폭이 3분의 1로 줄어들 수 있습니다.
### 캐시 일관성 및 동기화 오버헤드
멀티프로세서 환경에서는 각 CPU가 로컬 캐시를 포함할 수 있기 때문에, 여러 스레드가 공유 데이터를 액세스할 때 **캐시 일관성**을 유지하는 문제가 발생합니다.
스레드들이 **뮤텍스 잠금**이나 **원자적 연산(atomic operations)** 과 같은 동기화 메커니즘을 사용하여 공유 데이터에 접근해야 한다면, 이러한 동기화 및 조정 작업 자체가 오버헤드를 발생시켜 성능 향상을 제한할 수 있습니다.

결론적으로, 스레드 개수가 고정되어 있더라도 코어가 증가하면 각 스레드가 더 많은 전용 리소스를 확보하여 최대 성능에 도달하기가 더 쉬워지지만, 그 이점은 프로그램의 **병렬화 정도(순차 실행 비율)**, **부하 균형**, 그리고 **스레드 간의 통신/동기화 비용**에 따라 결정됩니다.

# 운영체제가 물리 메모리를 관리하는 방식
운영체제 및 하드웨어는 메모리 계층 구조를 관리하여 프로그래머에게 마치 **메인 메모리가 계층 구조의 최상단만큼 빠르고, 최하단만큼 크고 저렴한 것처럼 보이는 환상**을 제공합니다.
운영체제는 메모리 계층 전반에 걸쳐 데이터의 일관성을 유지하고 주소를 변환하는 역할을 담당합니다.
## 메모리 일관성 및 쓰기 정책
만약 저장소 명령(store instruction) 시 캐시에만 데이터를 쓰고 메인 메모리는 변경하지 않는다면, 캐시와 메모리가 일관성이 없는 상태가 됩니다.

1. **Write-Through**: 메인 메모리와 캐시를 일관되게 유지하는 가장 간단한 방법은 데이터를 항상 메모리와 캐시 **모두에** 쓰는 것입니다. 이 방식은 **쓰기 지연 시간을 숨기기 위해 write buffer를 사용**할 필요가 있습니다.

2. **Write-Back**: 블록이 교체될 때 해당 블록을 메모리로 복사하는 방식입니다. 가상 메모리 시스템에서는 디스크에 데이터를 기록하는 데 수백만 클럭 사이클이 소요될 수 있으므로, 쓰기 버퍼를 사용하여 쓰루 방식을 구현하는 것이 비현실적입니다. 따라서 **가상 메모리 시스템은 반드시 write-back 방식을 사용**해야 합니다. 이 방식은 쓰기 시 캐시 블록에 **dirty bit**를 설정해야 합니다.
## 주소 변환 및 TLB
운영체제가 가상 주소를 물리 주소로 변환하여 메모리 계층에 접근할 때, **TLB(Translation Lookaside Buffer)** 가 중요하게 작용합니다.
- TLB에서 히트가 발생하면, 결과로 생성된 **물리 주소**를 사용하여 캐시에 접근할 수 있습니다.
- **캐시 히트**는 **TLB 히트가 발생한 후에만** 일어날 수 있으며, 이는 요청된 데이터가 메모리에 존재함을 의미합니다.
### TLB의 물리적 위치
TLB는 컴퓨터 중앙 처리 장치(CPU) 내부에 위치합니다.
- **MMU의 일부**: TLB는 **메모리 관리 장치(MMU; Memory-Management Unit)** 내에 존재하는 특수한 하드웨어입니다. MMU는 논리 주소를 물리 주소로 동적으로 매핑하는 하드웨어 장치이며, TLB는 이 MMU의 핵심 부분입니다.
- **고속 캐시**: TLB는 **특수하고, 작으며, 빠른 탐색(fast-lookup) 하드웨어 캐시**로 불립니다. 이는 **연관성 메모리(associative memory)** 로 구현되어 검색 속도가 매우 빠릅니다.
- **명령어 파이프라인의 일부**: TLB 조회는 현대 하드웨어에서 명령어 파이프라인의 일부로 수행되며, 사실상 성능 저하를 일으키지 않습니다.
- **크기 및 구조**: TLB는 일반적으로 **32개에서 1,024개** 정도의 항목을 가질 만큼 작게 유지됩니다. 일부 CPU(e.g. ARM 아키텍처)는 데이터용 TLB와 명령어용 TLB를 분리한 **마이크로 TLB**와 더불어 **메인 TLB**를 포함하는 **두 단계의 TLB**를 구현하기도 합니다.
### TLB의 역할
TLB는 메모리 계층 구조의 성능을 개선합니다.
- **주소 변환 가속화**: TLB는 **최근에 사용된 가상 주소-물리 주소 변환(address mappings)** 정보를 저장하여 **페이지 테이블 접근을 피하기 위한 캐시** 역할을 합니다.
- **메모리 접근 지연 방지**: 페이지 테이블 자체가 주 메모리에 저장되어 있기 때문에, TLB가 없으면 데이터에 접근할 때마다 **페이지 테이블 접근 1회 + 실제 데이터 접근 1회**로 인해 메모리 접근 시간이 두 배로 느려질 수 있습니다. TLB는 이러한 지연을 방지합니다.
- **페이지 테이블 엔트리 저장**: 각 TLB 항목은 가상 페이지 번호의 일부를 태그(tag)로 보유하고, 해당 물리 페이지 번호를 데이터로 보유합니다.
- **상태 정보 포함**: TLB는 단순히 주소 변환 정보 외에도 해당 페이지에 대한 다른 상태 비트를 포함해야 합니다. 여기에는 **Dirty 비트(수정 여부)**, **Reference/Use 비트(사용 여부)**, 그리고 **쓰기 접근 비트(Write access bit)** 와 같은 보호 메커니즘이 포함될 수 있습니다.
- **프로세스 주소 공간 보호**: 일부 TLB는 **주소 공간 식별자(ASID; Address-Space Identifier)** 를 저장하여 각 프로세스를 고유하게 식별합니다. 이는 현재 실행 중인 프로세스의 ASID와 TLB 항목의 ASID가 일치할 때만 TLB 히트를 허용하여, 프로세스 간의 **주소 공간 보호**를 제공합니다.
### TLB의 동작 방식
TLB는 CPU가 논리 주소를 생성할 때마다 다음과 같은 절차로 작동합니다.
1. 논리 주소에서 페이지 번호 추출 및 TLB 조회
	- CPU가 논리 주소를 생성하면, MMU는 논리 주소에서 페이지 번호를 추출하고 TLB에 해당 페이지 번호가 존재하는지 확인합니다. TLB는 연관성 메모리이므로, 이 조회 과정에서 모든 키와 동시에 비교가 이루어집니다.
2. TLB 히트 시
	- 페이지 번호가 TLB에서 발견되면(hit), 해당 프레임 번호가 즉시 확보됩니다.
	- 이 프레임 번호는 논리 주소의 페이지 오프셋과 결합되어 물리 주소를 생성하며, 이를 이용해 주 메모리에 접근합니다.
	- 이 과정은 명령어 파이프라인의 일부로 실행되므로 성능 페널티가 발생하지 않습니다.
3. TLB 미스 시
	- 페이지 번호가 TLB에 없으면(miss), 주소 변환은 **페이지 테이블이 저장된 주 메모리를 참조**하여 진행됩니다. 이 과정은 **page table walk**라고 불리며, MMU가 메모리의 페이지 테이블을 탐색하여 필요한 변환 정보를 찾는 것입니다.
		- 페이지가 메모리에 있는 경우(**TLB miss, page table hit**): 페이지 테이블에서 프레임 번호를 가져온 후, 이를 사용하여 메모리에 접근합니다. 이 변환 정보(페이지 번호와 프레임 번호 쌍)는 향후 빠른 접근을 위해 TLB에 추가됩니다.
		- 페이지가 메모리에 없는 경우(**page fault**): 페이지 테이블 항목의 유효 비트가 꺼져 있으면, **페이지가 현재 주 메모리에 없고 디스크에 있음을 의미하는 page fault**가 발생합니다. 이 경우, 프로세서는 예외를 발생시켜 운영체제가 디스크에서 해당 페이지를 메모리로 가져오도록 합니다.
	- TLB 교체 정책: TLB가 가득 차서 새로운 항목을 추가해야 하는 경우, LRU(Least Recently Used), 라운드 로빈, 랜덤 등의 교체 정책에 따라 기존 항목이 교체됩니다.
4. TLB 관리
	- ASID를 사용하는 시스템: TLB가 ASID를 지원하면, context switch가 발생해도 TLB를 플러시(erased)할 필요가 없습니다.

### 264p
- 스레드 전용 저장소에 메모리 풀을 넣는 경우, 스레드A의 실행이 완료된 후에도 스레드B에서 해당 메모리를 계속 사용한다면 스레드B에서 스레드A의 메모리를 해제해야하는데, 이를 어떻게 해결하는가?
### 265p
- 매개변수를 이용해 함수 내에서 계산한 값이 할당된 변수도 지역변수라면, 이 변수를 반환하는 함수 호출이 끝났을때 해당 변수도 무효화되나?
> javascript는 원시타입(number, string, boolean 등)에 대해 값을 복사하여 전달하는 방식으로 동작한다. 그러므로 반환값은 함수 외부로 복사되어 전달되며, 외부 변수는 새로운 메모리 공간에 값을 할당한다.

```ts
const getSum = (a: number, b: number) => {
	const result = a + b; // result는 지역변수
	return result; // result 값이 복사되어 반환됨
}
const sum = getSum(1, 2); // sum은 3이라는 값을 받음
// 이 시점에서 getSum 함수의 result 변수는 이미 무효화됨
```

> java는 원시 타입(int, double, boolean 등)은 값을 복사하고, 객체 타입은 참조(reference)를 복사한다. 함수가 객체를 반환해도 해당 객체는 힙 메모리에 저장되있기 때문에 함수 호출이 끝나고  지역 변수가 무효화되어도 객체는 힙메모리에 존재하므로 함수 외부 변수에 할당할 수 있다.

```java
public class Example {
    public Person createPerson() {
        Person person = new Person("John"); // 힙 메모리에 객체 생성
        return person; // 객체의 참조를 반환
    }

    public static void main(String[] args) {
        Example ex = new Example();
        Person result = ex.createPerson(); // result는 여전히 유효한 Person 객체를 참조
        System.out.println(result.getName()); // 정상 작동
    }
}
```


### 288p
- 메모리 셀에 비트를 저장하려면 전원이 켜져있는 한, 계속해서 단자에 비트를 입력해야하는가?
### 296p
- 프로세스 대기열에는 항상 System Idle Process가 준비 완료 상태로 있기 때문에 스케줄러가 대기열에서 항상 실행할 수 있는 프로세스를 찾을 수 있는 것인가?

### 306p
- 8이상의 숫자를 2진법과 2의 보수를 사용해서 어떻게 덧셈하는가?

### 320p
- 코어가 많을수록 코어 하나에 할당할 수 있는 스레드가 적어지니까 성능이 향상되나?

### 344p
- 스택 레지스터가 뭔지? 스택 포인터와 어떤 관련이 있는지?

### 345p
- 여러 프로그램들이 실행 중이면 PC 레지스터에는 어떻게 프로그램의 기계 명령어 주소가 저장되는지?

### 350p
- 프로그램이 실행되면 사용자 상태 스레드가 생성될때마다 자동으로 커널 상태 스택을 갖고 생성되는가?

### 351p
- 사용자 상태 스레드의 컨텍스트(실행 상황) 정보가 어떤 방법으로 커널 상태 스택에 저장되는가?

### 352p
- 동시에 여러 작업을 해야할때, CPU는 어떻게 사용자 상태와 커널 상태를 동시에 수행할 수 있는가?
- 상태(mode)는 코어에 적용되는 건가?

### 357p
- 스레드가 전환될때 스레드의 상황정보를 저장하고 복원하는 주체는 커널 상태에서 커널 안의 타이머 인터럽트 처리 프로그램인가?
- 타이머 인터럽트 처리 프로그램은 스레드가 생성될때 내장되는 건가?

### 358p
- CPU 시간 조각이 모두 사용됐는데 어떻게 스레드가 사용자 상태로 돌아가서 실행될 수 있는가?

### 366p
- CPU 코어는 캐시(L1, L2, L3)에 어떻게 접근하는가?
- 운영체제가 캐시에 접근하는 기계 명령어를 제공해주는 건가?

### 387p
- 언어 별로 배열을 저장할때 행 우선 방식인지, 열 우선 방식인지 알아두기
- 언어 설정에서 배열 저장 방식을 바꿀 수 있는지 알아두기

### 408 - 412p
- 메모리 장벽 이해 안됌

### 426p
- CPU는 메모리 주소 공간만 가지고 메모리에서 데이터를 읽어오는가?
- 장치 레지스터는 얼마나 많은 데이터를 저장할 수 있는가?

### 427p
- 장치 레지스터에 할당된 주소 공간의 특정 주소에 담긴 데이터가 장치 레지스터에 적재되는 것인지, 단순히 매핑되는 건지?
	- 장치 레지스터는 장치의 데이터를 저장하고, 메모리의 주소공간의 특정 주소가 장치 레지스터에 매핑된다.

### 433p
- 장치는 어떻게 CPU에게 인터럽트 신호를 보내는가?

### 442P
- 장치 버퍼는 무엇인가? 메모리에도 버퍼가 있나?

### 445p
-  DMA(direct memory access)는 어떻게 장치 입출력을 처리하는 별도의 스레드를 만드는가?
- 디스크 스레드는 CPU 스레드에 자신의 작업이 끝났다는 것을 어떻게 알리는가?

### 451p
- 운영체제는 어떻게 준비 완료 대기열에 프로세스를 넣는가?
- 운영체제는 준비 완료 대기열에서 프로세스를 어떻게 꺼내어 CPU에 할당하는가?